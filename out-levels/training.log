root - WARNING - step 0: train loss 2.201447, val loss 2.247372, lr 0.000000, mfu -100.00%
root - WARNING - step 250: train loss 0.586844, val loss 0.732817, lr 0.010000, mfu 0.18%
root - WARNING - step 500: train loss 0.564112, val loss 0.705756, lr 0.009998, mfu 0.18%
root - WARNING - step 750: train loss 0.563617, val loss 0.707833, lr 0.009996, mfu 0.19%
root - WARNING - step 1000: train loss 0.568537, val loss 0.700856, lr 0.009992, mfu 0.18%
root - WARNING - step 1250: train loss 0.553920, val loss 0.698966, lr 0.009987, mfu 0.18%
root - WARNING - step 1500: train loss 0.561423, val loss 0.702040, lr 0.009981, mfu 0.18%
root - WARNING - step 1750: train loss 0.561990, val loss 0.704347, lr 0.009973, mfu 0.18%
root - WARNING - step 2000: train loss 0.544939, val loss 0.687296, lr 0.009965, mfu 0.18%
root - WARNING - step 2250: train loss 0.551000, val loss 0.700691, lr 0.009955, mfu 0.18%
root - WARNING - step 2500: train loss 0.554355, val loss 0.695241, lr 0.009944, mfu 0.18%
root - WARNING - step 2750: train loss 0.546204, val loss 0.698167, lr 0.009931, mfu 0.18%
root - WARNING - step 3000: train loss 0.550102, val loss 0.694459, lr 0.009918, mfu 0.17%
root - WARNING - step 3250: train loss 0.542947, val loss 0.698562, lr 0.009903, mfu 0.19%
root - WARNING - step 3500: train loss 0.546188, val loss 0.683888, lr 0.009887, mfu 0.19%
root - WARNING - step 3750: train loss 0.544244, val loss 0.686852, lr 0.009870, mfu 0.19%
root - WARNING - step 4000: train loss 0.540141, val loss 0.681882, lr 0.009852, mfu 0.18%
root - WARNING - step 4250: train loss 0.543233, val loss 0.691825, lr 0.009832, mfu 0.18%
root - WARNING - step 4500: train loss 0.552128, val loss 0.686415, lr 0.009811, mfu 0.19%
root - WARNING - step 4750: train loss 0.538000, val loss 0.679617, lr 0.009789, mfu 0.19%
root - WARNING - step 5000: train loss 0.541803, val loss 0.690556, lr 0.009766, mfu 0.19%
root - WARNING - step 5250: train loss 0.543421, val loss 0.683344, lr 0.009742, mfu 0.19%
root - WARNING - step 5500: train loss 0.550028, val loss 0.684172, lr 0.009717, mfu 0.19%
root - WARNING - step 5750: train loss 0.541472, val loss 0.680226, lr 0.009690, mfu 0.18%
root - WARNING - step 6000: train loss 0.544320, val loss 0.677824, lr 0.009662, mfu 0.19%
root - WARNING - step 6250: train loss 0.535180, val loss 0.680191, lr 0.009634, mfu 0.19%
root - WARNING - step 6500: train loss 0.540250, val loss 0.681723, lr 0.009604, mfu 0.19%
root - WARNING - step 6750: train loss 0.536463, val loss 0.680517, lr 0.009572, mfu 0.20%
root - WARNING - step 7000: train loss 0.538282, val loss 0.677788, lr 0.009540, mfu 0.18%
root - WARNING - step 7250: train loss 0.538616, val loss 0.680468, lr 0.009507, mfu 0.19%
root - WARNING - step 7500: train loss 0.536148, val loss 0.678022, lr 0.009472, mfu 0.19%
root - WARNING - step 7750: train loss 0.530229, val loss 0.680170, lr 0.009437, mfu 0.18%
root - WARNING - step 8000: train loss 0.537290, val loss 0.676574, lr 0.009400, mfu 0.20%
root - WARNING - step 8250: train loss 0.544809, val loss 0.683136, lr 0.009363, mfu 0.19%
root - WARNING - step 8500: train loss 0.532568, val loss 0.682150, lr 0.009324, mfu 0.18%
root - WARNING - step 8750: train loss 0.535703, val loss 0.670559, lr 0.009284, mfu 0.19%
root - WARNING - step 9000: train loss 0.542679, val loss 0.675507, lr 0.009243, mfu 0.18%
root - WARNING - step 9250: train loss 0.537418, val loss 0.677950, lr 0.009201, mfu 0.18%
root - WARNING - step 9500: train loss 0.534937, val loss 0.675342, lr 0.009158, mfu 0.18%
root - WARNING - step 9750: train loss 0.529327, val loss 0.673358, lr 0.009114, mfu 0.19%
root - WARNING - step 10000: train loss 0.532886, val loss 0.673029, lr 0.009069, mfu 0.18%
root - WARNING - step 10250: train loss 0.537864, val loss 0.674607, lr 0.009023, mfu 0.19%
root - WARNING - step 10500: train loss 0.529878, val loss 0.677476, lr 0.008976, mfu 0.18%
root - WARNING - step 10750: train loss 0.528824, val loss 0.665740, lr 0.008928, mfu 0.19%
root - WARNING - step 11000: train loss 0.532643, val loss 0.678910, lr 0.008879, mfu 0.18%
root - WARNING - step 11250: train loss 0.529480, val loss 0.666176, lr 0.008830, mfu 0.18%
root - WARNING - step 11500: train loss 0.531094, val loss 0.676013, lr 0.008779, mfu 0.18%
root - WARNING - step 11750: train loss 0.528722, val loss 0.671121, lr 0.008727, mfu 0.18%
root - WARNING - step 12000: train loss 0.538853, val loss 0.670629, lr 0.008675, mfu 0.18%
root - WARNING - step 12250: train loss 0.533687, val loss 0.671551, lr 0.008621, mfu 0.18%
root - WARNING - step 12500: train loss 0.539870, val loss 0.675583, lr 0.008567, mfu 0.19%
root - WARNING - step 12750: train loss 0.527011, val loss 0.678339, lr 0.008511, mfu 0.18%
root - WARNING - step 13000: train loss 0.533345, val loss 0.673347, lr 0.008455, mfu 0.18%
root - WARNING - step 13250: train loss 0.521468, val loss 0.670680, lr 0.008398, mfu 0.18%
root - WARNING - step 13500: train loss 0.522342, val loss 0.665326, lr 0.008341, mfu 0.19%
root - WARNING - step 13750: train loss 0.526273, val loss 0.661343, lr 0.008282, mfu 0.18%
root - WARNING - step 14000: train loss 0.534626, val loss 0.670684, lr 0.008223, mfu 0.18%
root - WARNING - step 14250: train loss 0.533031, val loss 0.668772, lr 0.008162, mfu 0.18%
root - WARNING - step 14500: train loss 0.518389, val loss 0.668601, lr 0.008101, mfu 0.19%
root - WARNING - step 14750: train loss 0.528150, val loss 0.664861, lr 0.008040, mfu 0.18%
root - WARNING - step 15000: train loss 0.531108, val loss 0.668368, lr 0.007977, mfu 0.19%
root - WARNING - step 15250: train loss 0.522443, val loss 0.667280, lr 0.007914, mfu 0.18%
root - WARNING - step 15500: train loss 0.530588, val loss 0.669592, lr 0.007850, mfu 0.18%
root - WARNING - step 15750: train loss 0.527574, val loss 0.669033, lr 0.007785, mfu 0.18%
root - WARNING - step 16000: train loss 0.521579, val loss 0.661641, lr 0.007720, mfu 0.18%
root - WARNING - step 16250: train loss 0.523526, val loss 0.667315, lr 0.007654, mfu 0.18%
root - WARNING - step 16500: train loss 0.532002, val loss 0.670216, lr 0.007588, mfu 0.19%
root - WARNING - step 16750: train loss 0.518548, val loss 0.668226, lr 0.007521, mfu 0.19%
root - WARNING - step 17000: train loss 0.529632, val loss 0.666949, lr 0.007453, mfu 0.18%
root - WARNING - step 17250: train loss 0.518351, val loss 0.665420, lr 0.007384, mfu 0.18%
root - WARNING - step 17500: train loss 0.519157, val loss 0.667124, lr 0.007315, mfu 0.19%
root - WARNING - step 17750: train loss 0.520759, val loss 0.659145, lr 0.007246, mfu 0.15%
root - WARNING - step 18000: train loss 0.520036, val loss 0.666589, lr 0.007176, mfu 0.18%
root - WARNING - step 18250: train loss 0.513762, val loss 0.665264, lr 0.007105, mfu 0.18%
root - WARNING - step 18500: train loss 0.520679, val loss 0.659721, lr 0.007034, mfu 0.18%
root - WARNING - step 18750: train loss 0.519949, val loss 0.663471, lr 0.006962, mfu 0.17%
root - WARNING - step 19000: train loss 0.524585, val loss 0.663945, lr 0.006890, mfu 0.18%
root - WARNING - step 19250: train loss 0.529362, val loss 0.660275, lr 0.006818, mfu 0.18%
root - WARNING - step 19500: train loss 0.526110, val loss 0.666096, lr 0.006745, mfu 0.17%
root - WARNING - step 19750: train loss 0.512200, val loss 0.661171, lr 0.006671, mfu 0.18%
root - WARNING - step 20000: train loss 0.514998, val loss 0.655240, lr 0.006597, mfu 0.18%
root - WARNING - step 20250: train loss 0.520112, val loss 0.662835, lr 0.006523, mfu 0.18%
root - WARNING - step 20500: train loss 0.513075, val loss 0.656935, lr 0.006449, mfu 0.18%
root - WARNING - step 20750: train loss 0.515333, val loss 0.655970, lr 0.006374, mfu 0.17%
root - WARNING - step 21000: train loss 0.514170, val loss 0.657196, lr 0.006299, mfu 0.17%
root - WARNING - step 21250: train loss 0.517947, val loss 0.660433, lr 0.006223, mfu 0.17%
root - WARNING - step 21500: train loss 0.528391, val loss 0.659174, lr 0.006147, mfu 0.18%
root - WARNING - step 21750: train loss 0.522183, val loss 0.652744, lr 0.006071, mfu 0.19%
root - WARNING - step 22000: train loss 0.519360, val loss 0.657241, lr 0.005995, mfu 0.18%
root - WARNING - step 22250: train loss 0.522845, val loss 0.660232, lr 0.005918, mfu 0.19%
root - WARNING - step 22500: train loss 0.509892, val loss 0.657844, lr 0.005841, mfu 0.18%
root - WARNING - step 22750: train loss 0.514327, val loss 0.659305, lr 0.005764, mfu 0.19%
root - WARNING - step 23000: train loss 0.516956, val loss 0.657540, lr 0.005687, mfu 0.18%
root - WARNING - step 23250: train loss 0.519735, val loss 0.652260, lr 0.005610, mfu 0.18%
root - WARNING - step 23500: train loss 0.512934, val loss 0.648988, lr 0.005532, mfu 0.19%
root - WARNING - step 23750: train loss 0.517465, val loss 0.654851, lr 0.005455, mfu 0.20%
root - WARNING - step 24000: train loss 0.521833, val loss 0.651934, lr 0.005377, mfu 0.18%
root - WARNING - step 24250: train loss 0.507851, val loss 0.655892, lr 0.005299, mfu 0.18%
root - WARNING - step 24500: train loss 0.510164, val loss 0.660766, lr 0.005221, mfu 0.18%
root - WARNING - step 24750: train loss 0.516803, val loss 0.651348, lr 0.005143, mfu 0.18%
root - WARNING - step 25000: train loss 0.520205, val loss 0.655625, lr 0.005066, mfu 0.17%
root - WARNING - step 25250: train loss 0.517421, val loss 0.657314, lr 0.004988, mfu 0.18%
root - WARNING - step 25500: train loss 0.518712, val loss 0.650431, lr 0.004910, mfu 0.18%
root - WARNING - step 25750: train loss 0.507117, val loss 0.647635, lr 0.004832, mfu 0.19%
root - WARNING - step 26000: train loss 0.511759, val loss 0.650004, lr 0.004754, mfu 0.18%
root - WARNING - step 26250: train loss 0.511476, val loss 0.655742, lr 0.004676, mfu 0.18%
root - WARNING - step 26500: train loss 0.517488, val loss 0.648160, lr 0.004599, mfu 0.19%
root - WARNING - step 26750: train loss 0.510841, val loss 0.652000, lr 0.004521, mfu 0.18%
root - WARNING - step 27000: train loss 0.502711, val loss 0.645148, lr 0.004444, mfu 0.16%
root - WARNING - step 27250: train loss 0.513209, val loss 0.656571, lr 0.004367, mfu 0.17%
root - WARNING - step 27500: train loss 0.506819, val loss 0.642849, lr 0.004290, mfu 0.18%
root - WARNING - step 27750: train loss 0.515639, val loss 0.642504, lr 0.004213, mfu 0.17%
root - WARNING - step 28000: train loss 0.508557, val loss 0.642324, lr 0.004136, mfu 0.17%
root - WARNING - step 28250: train loss 0.503978, val loss 0.651622, lr 0.004059, mfu 0.18%
root - WARNING - step 28500: train loss 0.509551, val loss 0.645494, lr 0.003983, mfu 0.18%
root - WARNING - step 28750: train loss 0.505883, val loss 0.646340, lr 0.003907, mfu 0.18%
root - WARNING - step 29000: train loss 0.504651, val loss 0.639990, lr 0.003832, mfu 0.18%
root - WARNING - step 29250: train loss 0.508398, val loss 0.650426, lr 0.003756, mfu 0.20%
root - WARNING - step 29500: train loss 0.505101, val loss 0.647549, lr 0.003681, mfu 0.18%
root - WARNING - step 29750: train loss 0.504963, val loss 0.639332, lr 0.003607, mfu 0.18%
root - WARNING - step 30000: train loss 0.502414, val loss 0.642885, lr 0.003532, mfu 0.18%
root - WARNING - step 30250: train loss 0.503225, val loss 0.641681, lr 0.003458, mfu 0.19%
root - WARNING - step 30500: train loss 0.504336, val loss 0.638234, lr 0.003385, mfu 0.20%
root - WARNING - step 30750: train loss 0.495876, val loss 0.644851, lr 0.003312, mfu 0.18%
root - WARNING - step 31000: train loss 0.504246, val loss 0.643072, lr 0.003239, mfu 0.20%
root - WARNING - step 31250: train loss 0.500196, val loss 0.642034, lr 0.003167, mfu 0.19%
root - WARNING - step 31500: train loss 0.504153, val loss 0.645183, lr 0.003095, mfu 0.19%
root - WARNING - step 31750: train loss 0.504044, val loss 0.640993, lr 0.003023, mfu 0.18%
root - WARNING - step 32000: train loss 0.503838, val loss 0.642273, lr 0.002953, mfu 0.20%
root - WARNING - step 32250: train loss 0.500311, val loss 0.642114, lr 0.002882, mfu 0.18%
root - WARNING - step 32500: train loss 0.503208, val loss 0.642135, lr 0.002812, mfu 0.19%
root - WARNING - step 32750: train loss 0.505648, val loss 0.638851, lr 0.002743, mfu 0.19%
root - WARNING - step 33000: train loss 0.500373, val loss 0.634089, lr 0.002675, mfu 0.19%
root - WARNING - step 33250: train loss 0.491139, val loss 0.638913, lr 0.002607, mfu 0.18%
root - WARNING - step 33500: train loss 0.500725, val loss 0.642869, lr 0.002539, mfu 0.18%
root - WARNING - step 33750: train loss 0.491770, val loss 0.639316, lr 0.002472, mfu 0.19%
root - WARNING - step 34000: train loss 0.502471, val loss 0.639073, lr 0.002406, mfu 0.19%
root - WARNING - step 34250: train loss 0.500963, val loss 0.639808, lr 0.002341, mfu 0.18%
root - WARNING - step 34500: train loss 0.498860, val loss 0.643018, lr 0.002276, mfu 0.18%
root - WARNING - step 34750: train loss 0.504008, val loss 0.639432, lr 0.002212, mfu 0.19%
root - WARNING - step 35000: train loss 0.493683, val loss 0.635181, lr 0.002148, mfu 0.19%
root - WARNING - step 35250: train loss 0.497770, val loss 0.641190, lr 0.002085, mfu 0.19%
root - WARNING - step 35500: train loss 0.500798, val loss 0.630585, lr 0.002023, mfu 0.20%
root - WARNING - step 35750: train loss 0.492296, val loss 0.638074, lr 0.001962, mfu 0.18%
root - WARNING - step 36000: train loss 0.491733, val loss 0.636221, lr 0.001901, mfu 0.18%
root - WARNING - step 36250: train loss 0.489517, val loss 0.635119, lr 0.001842, mfu 0.18%
root - WARNING - step 36500: train loss 0.494377, val loss 0.632636, lr 0.001783, mfu 0.19%
root - WARNING - step 36750: train loss 0.501881, val loss 0.637153, lr 0.001725, mfu 0.18%
root - WARNING - step 37000: train loss 0.491020, val loss 0.637237, lr 0.001667, mfu 0.19%
root - WARNING - step 37250: train loss 0.487845, val loss 0.634948, lr 0.001611, mfu 0.18%
root - WARNING - step 37500: train loss 0.486700, val loss 0.636295, lr 0.001555, mfu 0.18%
root - WARNING - step 37750: train loss 0.490958, val loss 0.633407, lr 0.001501, mfu 0.20%
root - WARNING - step 38000: train loss 0.495552, val loss 0.633745, lr 0.001447, mfu 0.20%
root - WARNING - step 38250: train loss 0.496942, val loss 0.623453, lr 0.001394, mfu 0.19%
root - WARNING - step 38500: train loss 0.485766, val loss 0.628486, lr 0.001342, mfu 0.19%
root - WARNING - step 38750: train loss 0.486628, val loss 0.629904, lr 0.001291, mfu 0.20%
root - WARNING - step 39000: train loss 0.496009, val loss 0.631927, lr 0.001240, mfu 0.19%
root - WARNING - step 39250: train loss 0.492113, val loss 0.632758, lr 0.001191, mfu 0.19%
root - WARNING - step 39500: train loss 0.483265, val loss 0.628651, lr 0.001143, mfu 0.18%
root - WARNING - step 39750: train loss 0.482417, val loss 0.629328, lr 0.001095, mfu 0.18%
root - WARNING - step 40000: train loss 0.484247, val loss 0.624176, lr 0.001049, mfu 0.19%
root - WARNING - step 40250: train loss 0.493754, val loss 0.629093, lr 0.001004, mfu 0.19%
root - WARNING - step 40500: train loss 0.484080, val loss 0.629172, lr 0.000959, mfu 0.20%
root - WARNING - step 40750: train loss 0.483820, val loss 0.625731, lr 0.000916, mfu 0.18%
root - WARNING - step 41000: train loss 0.479609, val loss 0.622920, lr 0.000874, mfu 0.18%
root - WARNING - step 41250: train loss 0.478903, val loss 0.620404, lr 0.000832, mfu 0.18%
root - WARNING - step 41500: train loss 0.482323, val loss 0.626748, lr 0.000792, mfu 0.19%
root - WARNING - step 41750: train loss 0.486530, val loss 0.625189, lr 0.000753, mfu 0.18%
root - WARNING - step 42000: train loss 0.477949, val loss 0.619849, lr 0.000715, mfu 0.18%
root - WARNING - step 42250: train loss 0.483605, val loss 0.626246, lr 0.000678, mfu 0.18%
root - WARNING - step 42500: train loss 0.487954, val loss 0.628249, lr 0.000642, mfu 0.18%
root - WARNING - step 42750: train loss 0.473285, val loss 0.632399, lr 0.000607, mfu 0.18%
root - WARNING - step 43000: train loss 0.483629, val loss 0.615154, lr 0.000573, mfu 0.19%
root - WARNING - step 43250: train loss 0.484030, val loss 0.626382, lr 0.000540, mfu 0.17%
root - WARNING - step 43500: train loss 0.476523, val loss 0.624422, lr 0.000509, mfu 0.18%
root - WARNING - step 43750: train loss 0.484688, val loss 0.623682, lr 0.000478, mfu 0.19%
root - WARNING - step 44000: train loss 0.478772, val loss 0.622421, lr 0.000449, mfu 0.19%
root - WARNING - step 44250: train loss 0.479721, val loss 0.623219, lr 0.000421, mfu 0.17%
root - WARNING - step 44500: train loss 0.479961, val loss 0.621412, lr 0.000394, mfu 0.19%
root - WARNING - step 44750: train loss 0.477126, val loss 0.616664, lr 0.000368, mfu 0.18%
root - WARNING - step 45000: train loss 0.475187, val loss 0.615265, lr 0.000343, mfu 0.19%
root - WARNING - step 45250: train loss 0.469607, val loss 0.623968, lr 0.000320, mfu 0.18%
root - WARNING - step 45500: train loss 0.476095, val loss 0.622012, lr 0.000297, mfu 0.18%
root - WARNING - step 45750: train loss 0.472161, val loss 0.618775, lr 0.000276, mfu 0.18%
root - WARNING - step 46000: train loss 0.477522, val loss 0.614258, lr 0.000256, mfu 0.19%
root - WARNING - step 46250: train loss 0.473912, val loss 0.618562, lr 0.000237, mfu 0.19%
root - WARNING - step 46500: train loss 0.478580, val loss 0.610952, lr 0.000220, mfu 0.18%
root - WARNING - step 46750: train loss 0.475967, val loss 0.618467, lr 0.000203, mfu 0.19%
root - WARNING - step 47000: train loss 0.476586, val loss 0.613487, lr 0.000188, mfu 0.19%
root - WARNING - step 47250: train loss 0.476854, val loss 0.614979, lr 0.000174, mfu 0.19%
root - WARNING - step 47500: train loss 0.469472, val loss 0.624288, lr 0.000161, mfu 0.19%
root - WARNING - step 47750: train loss 0.474340, val loss 0.617303, lr 0.000150, mfu 0.19%
root - WARNING - step 48000: train loss 0.475702, val loss 0.620338, lr 0.000139, mfu 0.19%
root - WARNING - step 48250: train loss 0.471179, val loss 0.617714, lr 0.000130, mfu 0.18%
root - WARNING - step 48500: train loss 0.475487, val loss 0.619645, lr 0.000122, mfu 0.18%
root - WARNING - step 48750: train loss 0.475336, val loss 0.616323, lr 0.000115, mfu 0.19%
root - WARNING - step 49000: train loss 0.472854, val loss 0.614533, lr 0.000110, mfu 0.20%
root - WARNING - step 49250: train loss 0.466471, val loss 0.620136, lr 0.000106, mfu 0.20%
root - WARNING - step 49500: train loss 0.479239, val loss 0.621620, lr 0.000102, mfu 0.19%
root - WARNING - step 49750: train loss 0.470055, val loss 0.617089, lr 0.000101, mfu 0.19%
root - WARNING - step 50000: train loss 0.472539, val loss 0.618645, lr 0.000100, mfu 0.18%
root - WARNING - step 50250: train loss 0.471101, val loss 0.618827, lr 0.000100, mfu 0.19%
root - WARNING - step 50500: train loss 0.472182, val loss 0.616711, lr 0.000100, mfu 0.15%
root - WARNING - step 50750: train loss 0.475433, val loss 0.618933, lr 0.000100, mfu 0.18%
root - WARNING - step 51000: train loss 0.473287, val loss 0.612473, lr 0.000100, mfu 0.19%
root - WARNING - step 51250: train loss 0.474285, val loss 0.618800, lr 0.000100, mfu 0.19%
root - WARNING - step 51500: train loss 0.467395, val loss 0.611772, lr 0.000100, mfu 0.19%
root - WARNING - step 51750: train loss 0.470637, val loss 0.614868, lr 0.000100, mfu 0.19%
root - WARNING - step 52000: train loss 0.478998, val loss 0.614685, lr 0.000100, mfu 0.19%
root - WARNING - step 52250: train loss 0.467879, val loss 0.619753, lr 0.000100, mfu 0.18%
root - WARNING - step 52500: train loss 0.472404, val loss 0.615560, lr 0.000100, mfu 0.20%
root - WARNING - step 52750: train loss 0.478843, val loss 0.611400, lr 0.000100, mfu 0.18%
root - WARNING - step 53000: train loss 0.467173, val loss 0.617599, lr 0.000100, mfu 0.18%
root - WARNING - step 53250: train loss 0.467190, val loss 0.623100, lr 0.000100, mfu 0.18%
root - WARNING - step 53500: train loss 0.469734, val loss 0.612625, lr 0.000100, mfu 0.17%
root - WARNING - step 53750: train loss 0.478749, val loss 0.613509, lr 0.000100, mfu 0.18%
root - WARNING - step 54000: train loss 0.475316, val loss 0.612261, lr 0.000100, mfu 0.20%
root - WARNING - step 54250: train loss 0.464967, val loss 0.615598, lr 0.000100, mfu 0.19%
root - WARNING - step 54500: train loss 0.463404, val loss 0.611617, lr 0.000100, mfu 0.18%
root - WARNING - step 54750: train loss 0.474399, val loss 0.609541, lr 0.000100, mfu 0.18%
root - WARNING - step 55000: train loss 0.474471, val loss 0.616652, lr 0.000100, mfu 0.17%
root - WARNING - step 55250: train loss 0.471171, val loss 0.610906, lr 0.000100, mfu 0.19%
root - WARNING - step 55500: train loss 0.470613, val loss 0.625628, lr 0.000100, mfu 0.19%
root - WARNING - step 55750: train loss 0.471880, val loss 0.616959, lr 0.000100, mfu 0.19%
root - WARNING - step 56000: train loss 0.475403, val loss 0.612253, lr 0.000100, mfu 0.20%
root - WARNING - step 56250: train loss 0.478951, val loss 0.613200, lr 0.000100, mfu 0.19%
root - WARNING - step 56500: train loss 0.472262, val loss 0.616982, lr 0.000100, mfu 0.18%
root - WARNING - step 56750: train loss 0.477985, val loss 0.615219, lr 0.000100, mfu 0.20%
root - WARNING - step 57000: train loss 0.468376, val loss 0.611686, lr 0.000100, mfu 0.19%
root - WARNING - step 57250: train loss 0.470989, val loss 0.620015, lr 0.000100, mfu 0.18%
root - WARNING - step 57500: train loss 0.471350, val loss 0.612664, lr 0.000100, mfu 0.19%
root - WARNING - step 57750: train loss 0.462174, val loss 0.617697, lr 0.000100, mfu 0.18%
root - WARNING - step 58000: train loss 0.472687, val loss 0.613833, lr 0.000100, mfu 0.18%
root - WARNING - step 58250: train loss 0.466641, val loss 0.618347, lr 0.000100, mfu 0.20%
root - WARNING - step 58500: train loss 0.472806, val loss 0.606538, lr 0.000100, mfu 0.18%
root - WARNING - step 58750: train loss 0.471227, val loss 0.614416, lr 0.000100, mfu 0.19%
root - WARNING - step 59000: train loss 0.467363, val loss 0.617499, lr 0.000100, mfu 0.19%
root - WARNING - step 59250: train loss 0.464191, val loss 0.615279, lr 0.000100, mfu 0.19%
root - WARNING - step 59500: train loss 0.475006, val loss 0.616801, lr 0.000100, mfu 0.19%
root - WARNING - step 59750: train loss 0.466756, val loss 0.614924, lr 0.000100, mfu 0.19%
root - WARNING - step 60000: train loss 0.468871, val loss 0.616696, lr 0.000100, mfu 0.19%
root - WARNING - step 60250: train loss 0.476845, val loss 0.617159, lr 0.000100, mfu 0.19%
root - WARNING - step 60500: train loss 0.460711, val loss 0.611162, lr 0.000100, mfu 0.18%
root - WARNING - step 60750: train loss 0.466340, val loss 0.613885, lr 0.000100, mfu 0.20%
root - WARNING - step 61000: train loss 0.468135, val loss 0.616602, lr 0.000100, mfu 0.18%
root - WARNING - step 61250: train loss 0.470100, val loss 0.614731, lr 0.000100, mfu 0.18%
root - WARNING - step 61500: train loss 0.468685, val loss 0.605165, lr 0.000100, mfu 0.18%
root - WARNING - step 61750: train loss 0.462165, val loss 0.611443, lr 0.000100, mfu 0.18%
root - WARNING - step 62000: train loss 0.467818, val loss 0.614138, lr 0.000100, mfu 0.18%
root - WARNING - step 62250: train loss 0.464786, val loss 0.607119, lr 0.000100, mfu 0.18%
root - WARNING - step 62500: train loss 0.474662, val loss 0.615383, lr 0.000100, mfu 0.18%
root - WARNING - step 62750: train loss 0.473425, val loss 0.607195, lr 0.000100, mfu 0.19%
root - WARNING - step 63000: train loss 0.472608, val loss 0.616036, lr 0.000100, mfu 0.19%
root - WARNING - step 63250: train loss 0.475417, val loss 0.616557, lr 0.000100, mfu 0.18%
root - WARNING - step 63500: train loss 0.473188, val loss 0.617037, lr 0.000100, mfu 0.18%
root - WARNING - step 63750: train loss 0.471061, val loss 0.619641, lr 0.000100, mfu 0.18%
root - WARNING - step 64000: train loss 0.465190, val loss 0.617475, lr 0.000100, mfu 0.18%
root - WARNING - step 64250: train loss 0.475237, val loss 0.614654, lr 0.000100, mfu 0.18%
root - WARNING - step 64500: train loss 0.470005, val loss 0.614728, lr 0.000100, mfu 0.18%
root - WARNING - step 64750: train loss 0.469925, val loss 0.611083, lr 0.000100, mfu 0.18%
root - WARNING - step 65000: train loss 0.468149, val loss 0.610338, lr 0.000100, mfu 0.18%
root - WARNING - step 65250: train loss 0.472651, val loss 0.615873, lr 0.000100, mfu 0.20%
root - WARNING - step 65500: train loss 0.476876, val loss 0.620422, lr 0.000100, mfu 0.18%
root - WARNING - step 65750: train loss 0.466755, val loss 0.607285, lr 0.000100, mfu 0.19%
root - WARNING - step 66000: train loss 0.471342, val loss 0.610886, lr 0.000100, mfu 0.19%
root - WARNING - step 66250: train loss 0.473062, val loss 0.615732, lr 0.000100, mfu 0.18%
root - WARNING - step 66500: train loss 0.478949, val loss 0.615367, lr 0.000100, mfu 0.19%
root - WARNING - step 66750: train loss 0.468390, val loss 0.613252, lr 0.000100, mfu 0.18%
root - WARNING - step 67000: train loss 0.478202, val loss 0.606535, lr 0.000100, mfu 0.18%
root - WARNING - step 67250: train loss 0.471628, val loss 0.612453, lr 0.000100, mfu 0.18%
root - WARNING - step 67500: train loss 0.468085, val loss 0.621454, lr 0.000100, mfu 0.19%
root - WARNING - step 67750: train loss 0.469996, val loss 0.611024, lr 0.000100, mfu 0.19%
root - WARNING - step 68000: train loss 0.468792, val loss 0.612667, lr 0.000100, mfu 0.18%
root - WARNING - step 68250: train loss 0.479290, val loss 0.614942, lr 0.000100, mfu 0.18%
root - WARNING - step 68500: train loss 0.468459, val loss 0.614327, lr 0.000100, mfu 0.18%
root - WARNING - step 68750: train loss 0.470810, val loss 0.610181, lr 0.000100, mfu 0.19%
root - WARNING - step 69000: train loss 0.475147, val loss 0.617334, lr 0.000100, mfu 0.17%
root - WARNING - step 69250: train loss 0.474674, val loss 0.615207, lr 0.000100, mfu 0.19%
root - WARNING - step 69500: train loss 0.474546, val loss 0.618661, lr 0.000100, mfu 0.17%
root - WARNING - step 69750: train loss 0.465486, val loss 0.616508, lr 0.000100, mfu 0.19%
root - WARNING - step 70000: train loss 0.469292, val loss 0.619310, lr 0.000100, mfu 0.18%
root - WARNING - step 70250: train loss 0.463481, val loss 0.611399, lr 0.000100, mfu 0.18%
root - WARNING - step 70500: train loss 0.477315, val loss 0.614829, lr 0.000100, mfu 0.18%
root - WARNING - step 70750: train loss 0.463443, val loss 0.614786, lr 0.000100, mfu 0.19%
root - WARNING - step 71000: train loss 0.467688, val loss 0.617992, lr 0.000100, mfu 0.19%
root - WARNING - step 71250: train loss 0.467000, val loss 0.618595, lr 0.000100, mfu 0.19%
root - WARNING - step 71500: train loss 0.471518, val loss 0.624185, lr 0.000100, mfu 0.18%
root - WARNING - step 71750: train loss 0.469124, val loss 0.608739, lr 0.000100, mfu 0.19%
root - WARNING - step 72000: train loss 0.471899, val loss 0.615288, lr 0.000100, mfu 0.18%
root - WARNING - step 72250: train loss 0.472908, val loss 0.612660, lr 0.000100, mfu 0.18%
root - WARNING - step 72500: train loss 0.472840, val loss 0.615828, lr 0.000100, mfu 0.19%
root - WARNING - step 72750: train loss 0.460579, val loss 0.617078, lr 0.000100, mfu 0.18%
root - WARNING - step 73000: train loss 0.469710, val loss 0.621008, lr 0.000100, mfu 0.18%
root - WARNING - step 73250: train loss 0.466618, val loss 0.607920, lr 0.000100, mfu 0.19%
root - WARNING - step 73500: train loss 0.474852, val loss 0.616371, lr 0.000100, mfu 0.19%
root - WARNING - step 73750: train loss 0.469015, val loss 0.616202, lr 0.000100, mfu 0.18%
root - WARNING - step 74000: train loss 0.469146, val loss 0.611064, lr 0.000100, mfu 0.18%
root - WARNING - step 74250: train loss 0.472002, val loss 0.615166, lr 0.000100, mfu 0.18%
root - WARNING - step 74500: train loss 0.467157, val loss 0.613395, lr 0.000100, mfu 0.18%
root - WARNING - step 74750: train loss 0.474525, val loss 0.616471, lr 0.000100, mfu 0.17%
root - WARNING - step 75000: train loss 0.470913, val loss 0.610168, lr 0.000100, mfu 0.19%
root - WARNING - step 75250: train loss 0.470736, val loss 0.616799, lr 0.000100, mfu 0.19%
root - WARNING - step 75500: train loss 0.468095, val loss 0.612550, lr 0.000100, mfu 0.19%
root - WARNING - step 75750: train loss 0.471373, val loss 0.611885, lr 0.000100, mfu 0.18%
root - WARNING - step 76000: train loss 0.472463, val loss 0.616757, lr 0.000100, mfu 0.18%
root - WARNING - step 76250: train loss 0.473751, val loss 0.609269, lr 0.000100, mfu 0.18%
root - WARNING - step 76500: train loss 0.468522, val loss 0.607770, lr 0.000100, mfu 0.18%
root - WARNING - step 76750: train loss 0.465916, val loss 0.615851, lr 0.000100, mfu 0.19%
root - WARNING - step 77000: train loss 0.465575, val loss 0.617035, lr 0.000100, mfu 0.18%
root - WARNING - step 77250: train loss 0.471437, val loss 0.614316, lr 0.000100, mfu 0.18%
root - WARNING - step 77500: train loss 0.473840, val loss 0.613411, lr 0.000100, mfu 0.18%
root - WARNING - step 77750: train loss 0.473383, val loss 0.609990, lr 0.000100, mfu 0.18%
root - WARNING - step 78000: train loss 0.462944, val loss 0.610169, lr 0.000100, mfu 0.19%
root - WARNING - step 78250: train loss 0.469516, val loss 0.608427, lr 0.000100, mfu 0.18%
root - WARNING - step 78500: train loss 0.467951, val loss 0.615421, lr 0.000100, mfu 0.18%
root - WARNING - step 78750: train loss 0.463837, val loss 0.611543, lr 0.000100, mfu 0.18%
root - WARNING - step 79000: train loss 0.467456, val loss 0.609400, lr 0.000100, mfu 0.19%
root - WARNING - step 79250: train loss 0.463614, val loss 0.614465, lr 0.000100, mfu 0.18%
root - WARNING - step 79500: train loss 0.462650, val loss 0.612973, lr 0.000100, mfu 0.18%
root - WARNING - step 79750: train loss 0.473583, val loss 0.609834, lr 0.000100, mfu 0.18%
root - WARNING - step 80000: train loss 0.468260, val loss 0.610167, lr 0.000100, mfu 0.18%
root - WARNING - step 80250: train loss 0.466024, val loss 0.618637, lr 0.000100, mfu 0.18%
root - WARNING - step 80500: train loss 0.466606, val loss 0.615670, lr 0.000100, mfu 0.19%
root - WARNING - step 80750: train loss 0.464743, val loss 0.610072, lr 0.000100, mfu 0.19%
root - WARNING - step 81000: train loss 0.472168, val loss 0.618129, lr 0.000100, mfu 0.18%
root - WARNING - step 81250: train loss 0.469283, val loss 0.614169, lr 0.000100, mfu 0.19%
root - WARNING - step 81500: train loss 0.470544, val loss 0.612129, lr 0.000100, mfu 0.19%
root - WARNING - step 81750: train loss 0.466483, val loss 0.614907, lr 0.000100, mfu 0.19%
root - WARNING - step 82000: train loss 0.467447, val loss 0.609634, lr 0.000100, mfu 0.18%
root - WARNING - step 82250: train loss 0.468905, val loss 0.615718, lr 0.000100, mfu 0.19%
root - WARNING - step 82500: train loss 0.470441, val loss 0.617033, lr 0.000100, mfu 0.18%
root - WARNING - step 82750: train loss 0.458018, val loss 0.614955, lr 0.000100, mfu 0.19%
root - WARNING - step 83000: train loss 0.468072, val loss 0.617949, lr 0.000100, mfu 0.17%
root - WARNING - step 83250: train loss 0.462644, val loss 0.613137, lr 0.000100, mfu 0.20%
root - WARNING - step 83500: train loss 0.471248, val loss 0.614818, lr 0.000100, mfu 0.19%
root - WARNING - step 83750: train loss 0.460436, val loss 0.614849, lr 0.000100, mfu 0.19%
root - WARNING - step 84000: train loss 0.465517, val loss 0.611333, lr 0.000100, mfu 0.18%
root - WARNING - step 84250: train loss 0.465713, val loss 0.610987, lr 0.000100, mfu 0.18%
root - WARNING - step 84500: train loss 0.464973, val loss 0.610232, lr 0.000100, mfu 0.19%
root - WARNING - step 84750: train loss 0.466124, val loss 0.609488, lr 0.000100, mfu 0.18%
root - WARNING - step 85000: train loss 0.464903, val loss 0.610651, lr 0.000100, mfu 0.19%
root - WARNING - step 85250: train loss 0.469815, val loss 0.611491, lr 0.000100, mfu 0.18%
root - WARNING - step 85500: train loss 0.462268, val loss 0.616267, lr 0.000100, mfu 0.19%
root - WARNING - step 85750: train loss 0.464541, val loss 0.607848, lr 0.000100, mfu 0.18%
root - WARNING - step 86000: train loss 0.461371, val loss 0.613624, lr 0.000100, mfu 0.19%
root - WARNING - step 86250: train loss 0.462272, val loss 0.612495, lr 0.000100, mfu 0.18%
root - WARNING - step 86500: train loss 0.470383, val loss 0.616145, lr 0.000100, mfu 0.19%
root - WARNING - step 86750: train loss 0.469268, val loss 0.612927, lr 0.000100, mfu 0.19%
root - WARNING - step 87000: train loss 0.476174, val loss 0.616024, lr 0.000100, mfu 0.19%
root - WARNING - step 87250: train loss 0.464476, val loss 0.609861, lr 0.000100, mfu 0.19%
root - WARNING - step 87500: train loss 0.462862, val loss 0.609322, lr 0.000100, mfu 0.19%
root - WARNING - step 87750: train loss 0.473297, val loss 0.609444, lr 0.000100, mfu 0.19%
root - WARNING - step 88000: train loss 0.463945, val loss 0.612166, lr 0.000100, mfu 0.19%
root - WARNING - step 88250: train loss 0.471700, val loss 0.606739, lr 0.000100, mfu 0.19%
root - WARNING - step 88500: train loss 0.467679, val loss 0.605931, lr 0.000100, mfu 0.19%
root - WARNING - step 88750: train loss 0.466310, val loss 0.620608, lr 0.000100, mfu 0.18%
root - WARNING - step 89000: train loss 0.466652, val loss 0.614386, lr 0.000100, mfu 0.19%
root - WARNING - step 89250: train loss 0.460340, val loss 0.610151, lr 0.000100, mfu 0.18%
root - WARNING - step 89500: train loss 0.465643, val loss 0.612791, lr 0.000100, mfu 0.18%
root - WARNING - step 89750: train loss 0.470969, val loss 0.609130, lr 0.000100, mfu 0.18%
root - WARNING - step 90000: train loss 0.471976, val loss 0.611683, lr 0.000100, mfu 0.19%
root - WARNING - step 90250: train loss 0.468580, val loss 0.608841, lr 0.000100, mfu 0.18%
root - WARNING - step 90500: train loss 0.463796, val loss 0.611211, lr 0.000100, mfu 0.19%
root - WARNING - step 90750: train loss 0.469124, val loss 0.616555, lr 0.000100, mfu 0.19%
root - WARNING - step 91000: train loss 0.465585, val loss 0.611504, lr 0.000100, mfu 0.18%
root - WARNING - step 91250: train loss 0.473715, val loss 0.616457, lr 0.000100, mfu 0.19%
root - WARNING - step 91500: train loss 0.478066, val loss 0.615466, lr 0.000100, mfu 0.19%
root - WARNING - step 91750: train loss 0.464597, val loss 0.617099, lr 0.000100, mfu 0.19%
root - WARNING - step 92000: train loss 0.466367, val loss 0.616661, lr 0.000100, mfu 0.19%
root - WARNING - step 92250: train loss 0.463972, val loss 0.608409, lr 0.000100, mfu 0.19%
root - WARNING - step 92500: train loss 0.474357, val loss 0.607988, lr 0.000100, mfu 0.18%
root - WARNING - step 92750: train loss 0.466710, val loss 0.611448, lr 0.000100, mfu 0.19%
root - WARNING - step 93000: train loss 0.471155, val loss 0.611282, lr 0.000100, mfu 0.19%
root - WARNING - step 93250: train loss 0.467817, val loss 0.617997, lr 0.000100, mfu 0.18%
root - WARNING - step 93500: train loss 0.463800, val loss 0.608559, lr 0.000100, mfu 0.20%
root - WARNING - step 93750: train loss 0.472533, val loss 0.614035, lr 0.000100, mfu 0.18%
root - WARNING - step 94000: train loss 0.470643, val loss 0.612843, lr 0.000100, mfu 0.18%
root - WARNING - step 94250: train loss 0.468773, val loss 0.611106, lr 0.000100, mfu 0.19%
root - WARNING - step 94500: train loss 0.468890, val loss 0.613679, lr 0.000100, mfu 0.18%
root - WARNING - step 94750: train loss 0.467890, val loss 0.606867, lr 0.000100, mfu 0.18%
root - WARNING - step 95000: train loss 0.470186, val loss 0.612834, lr 0.000100, mfu 0.18%
root - WARNING - step 95250: train loss 0.464339, val loss 0.609388, lr 0.000100, mfu 0.19%
root - WARNING - step 95500: train loss 0.466154, val loss 0.612442, lr 0.000100, mfu 0.18%
root - WARNING - step 95750: train loss 0.470059, val loss 0.611022, lr 0.000100, mfu 0.19%
root - WARNING - step 96000: train loss 0.455014, val loss 0.617505, lr 0.000100, mfu 0.18%
root - WARNING - step 96250: train loss 0.466272, val loss 0.612412, lr 0.000100, mfu 0.18%
root - WARNING - step 96500: train loss 0.461598, val loss 0.613097, lr 0.000100, mfu 0.20%
root - WARNING - step 96750: train loss 0.466897, val loss 0.615077, lr 0.000100, mfu 0.19%
root - WARNING - step 97000: train loss 0.464851, val loss 0.613468, lr 0.000100, mfu 0.18%
root - WARNING - step 97250: train loss 0.469127, val loss 0.610727, lr 0.000100, mfu 0.19%
root - WARNING - step 97500: train loss 0.465009, val loss 0.607544, lr 0.000100, mfu 0.18%
root - WARNING - step 97750: train loss 0.463604, val loss 0.613056, lr 0.000100, mfu 0.18%
root - WARNING - step 98000: train loss 0.468330, val loss 0.609563, lr 0.000100, mfu 0.20%
root - WARNING - step 98250: train loss 0.463261, val loss 0.615724, lr 0.000100, mfu 0.21%
root - WARNING - step 98500: train loss 0.462760, val loss 0.604958, lr 0.000100, mfu 0.18%
root - WARNING - step 98750: train loss 0.465724, val loss 0.604571, lr 0.000100, mfu 0.18%
root - WARNING - step 99000: train loss 0.468235, val loss 0.619683, lr 0.000100, mfu 0.19%
root - WARNING - step 99250: train loss 0.464891, val loss 0.613895, lr 0.000100, mfu 0.19%
root - WARNING - step 99500: train loss 0.465177, val loss 0.611082, lr 0.000100, mfu 0.19%
root - WARNING - step 99750: train loss 0.464506, val loss 0.610882, lr 0.000100, mfu 0.19%
root - WARNING - step 100000: train loss 0.463255, val loss 0.616532, lr 0.000100, mfu 0.19%
